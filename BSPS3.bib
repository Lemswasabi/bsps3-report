% Encoding: UTF-8
@book{Goodfellow-et-al-2016,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    year={2016}
}

@misc{Python,
        title = {Python Software Foundation, Python Language Reference, version
                3.7. Available at},
        note = {\url{http://www.python.org/}}
}

@misc{chollet2015keras,
  title={Keras},
  author={Chollet, Fran\c{c}ois and others},
  year={2015},
  howpublished={\url{https://keras.io}},
}

@misc{PyRO,
        title = {General Python FAQ},
        note = {\url{https://docs.python.org/3/faq/general.html#what-is-python},
                accessed {19/05/19}}
}

@article{DBLP:journals/corr/abs-1804-03209,
  author    = {Pete Warden},
  title     = {Speech Commands: {A} Dataset for Limited-Vocabulary Speech Recognition},
  journal   = {CoRR},
  volume    = {abs/1804.03209},
  year      = {2018},
  url       = {http://arxiv.org/abs/1804.03209},
  archivePrefix = {arXiv},
  eprint    = {1804.03209},
  timestamp = {Mon, 13 Aug 2018 16:48:32 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1804-03209},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/AmodeiABCCCCCCD15,
  author    = {Dario Amodei and
               Rishita Anubhai and
               Eric Battenberg and
               Carl Case and
               Jared Casper and
               Bryan Catanzaro and
               Jingdong Chen and
               Mike Chrzanowski and
               Adam Coates and
               Greg Diamos and
               Erich Elsen and
               Jesse H. Engel and
               Linxi Fan and
               Christopher Fougner and
               Tony Han and
               Awni Y. Hannun and
               Billy Jun and
               Patrick LeGresley and
               Libby Lin and
               Sharan Narang and
               Andrew Y. Ng and
               Sherjil Ozair and
               Ryan Prenger and
               Jonathan Raiman and
               Sanjeev Satheesh and
               David Seetapun and
               Shubho Sengupta and
               Yi Wang and
               Zhiqian Wang and
               Chong Wang and
               Bo Xiao and
               Dani Yogatama and
               Jun Zhan and
               Zhenyao Zhu},
  title     = {Deep Speech 2: End-to-End Speech Recognition in English and Mandarin},
  journal   = {CoRR},
  volume    = {abs/1512.02595},
  year      = {2015},
  url       = {http://arxiv.org/abs/1512.02595},
  archivePrefix = {arXiv},
  eprint    = {1512.02595},
  timestamp = {Mon, 22 Jul 2019 13:51:23 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/AmodeiABCCCCCCD15},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{Williamsong,
  author    = {William Song
               Jim Cai},
  title     = {End-to-End Deep Neural Network for AutomaticSpeech Recognition},
  year      = {2015},
  url       = {https://cs224d.stanford.edu/reports/SongWilliam.pdf},
}

@misc{mfcc,
        title = {Mel Frequency Cepstral Coefficient (MFCC) tutorial},
        note =
        {\url{http://practicalcryptography.com/miscellaneous/machine-learning/guide-mel-frequency-cepstral-coefficients-mfccs/#references},
        accessed {02/12/19}}
}
@article{doi:10.1162/neco.1997.9.8.1735,
  author = {Hochreiter, Sepp and Schmidhuber, J√ºrgen},
  title = {Long Short-Term Memory},
  journal = {Neural Computation},
  volume = {9},
  number = {8},
  pages = {1735-1780},
  year = {1997},
  doi = {10.1162/neco.1997.9.8.1735},
  URL = {https://doi.org/10.1162/neco.1997.9.8.1735},
  eprint = {https://doi.org/10.1162/neco.1997.9.8.1735},
  abstract = { Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms. }
}
@article{DBLP:journals/corr/ChungGCB14,
  author    = {Junyoung Chung and
               {\c{C}}aglar G{\"{u}}l{\c{c}}ehre and
               KyungHyun Cho and
               Yoshua Bengio},
  title     = {Empirical Evaluation of Gated Recurrent Neural Networks on Sequence
               Modeling},
  journal   = {CoRR},
  volume    = {abs/1412.3555},
  year      = {2014},
  url       = {http://arxiv.org/abs/1412.3555},
  archivePrefix = {arXiv},
  eprint    = {1412.3555},
  timestamp = {Mon, 13 Aug 2018 16:47:38 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/ChungGCB14},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@misc{librosa,
  autor     = {Brian McFee, Vincent Lostanlen, Matt McVicar, Alexandros Metsai,
               Stefan Balke, Carl Thomé, Adam Weiss},
  version   = {0.7.1},
  url       = {http://doi.org/10.5281/zenodo.3478579}
}
Comment{jabref-meta: databaseType:bibtex;}
