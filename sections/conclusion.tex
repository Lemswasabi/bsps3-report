% corrected LN 74

\section{Conclusion}

In this paper, end-to-end isolated word recognition using deep neural networks
is presented. Four different ANN models were investigated. The focus of this
paper is using RNN architectures for end-to-end speech recognition and
investigating whether gated RNNs outperform vanilla RNN units and how they deal
with long-term dependencies. The results showed, that gated RNNs substantially
outperform basic feedforward and recurrent neural networks. The performance
analysis can be consulted in Section~\ref{assessment}\\

A further objective of this paper is to recognize Luxembourgish words. To the
best of our knowledge, there is a lack of continuous speech dataset in
Luxembourgish. Thus efforts were put to collect a small dataset containing
Luxembourgish spoken words $w \in \{'Null',\dots,'Neng'\}$. This dataset was
recorded by one person which makes it speaker-dependent speech recognition. In
Section~\ref{datasetlux} the methods used to collect the dataset were
elaborated. Four previously discussed ANN architectures were applied to our
collected Luxembourgish dataset and yielded excellent performance with accuracy
close to 1.\\

Continuation of this project would be to extend the Luxembourgish dataset with
continuous speech or to add instances spoken by multiple speakers.\\

In my opinion, I find it interesting to work with deep neural networks and their
practical use. This project will give me the required background to start on my
next BSP which deals with attention-based models for speech recognition.
