% corrected VD 89

\subsubsection{Feedforward Neural Network}~\\

Feedforward neural networks or multilayer perceptrons (MLPs) are very important
deep learning models. The objective of MLPs is to approximate a given function
$f^{*}$. A feedforward network defines a mapping $\bm{\hat{y}} = f(\bm{x};
\bm{\theta})$ and learns the values of the parameter $\bm{\theta}$ with a given
input vector $\bm{x}$ which yields the best approximation of $f^{*}$. This
function can be for example a classifier, $y = f^{*}(\bm{x})$ which maps an
input $\bm{x}$ to a class $y$.\\

These structures are called \textbf{feedforward} since there is a progress of
information in one direction: From input to output.\\

MLPs are considered \textbf{networks} because they are made up of composed
functions. Let $f_{1}$, $f_{2}$ and $f_{3}$ be three function forming a chain
$f(\bm{x}) = f_{3}(f_{2}(f_{1}(\bm{x})))$. The chain structures are commonly
used in ANNs. In this example, $f_{1}$ is called the first layer of the network,
$f_{2}$ is the second layer, etc. The lenght of the chain represents the depth
of the network. The final layer is also called the output layer.\\

During the training of the neural network, we try to find $f(\bm{x})$ to
approximate $f^{*}(\bm{x})$. The training data contains examples of
$f^{*}(\bm{x})$ obtained with different training points where every example
$\bm{x}$ is referring to a label $y \approx f^{*}(\bm{x})$. These examples
determine how the output layer should approximate a value close to $y$ with each
example $\bm{x}$. The other layers are called the \textbf{hidden layers} because
the training examples are not determining their behaviour and it does not
contain the desired output of each layer. Therefore, a learning algorithm has to
determine how to utilize the hidden layers to obtain a good approximation of
$f^{*}(\bm{x})$.\\

The \textbf{width} of the feedforward model is defined by the dimensionality of
each hidden layer which is usually a vector containing values. These vector
layers contain many \textbf{units} which process data in parallel. Each unit
refers to a vector-to-scalar function, by taking input from other units and
calculating its proper activation value.\\

We will present a simple MLP with one hidden layer which contains hidden units.
The hidden layer represents a vector of hidden units $\bm{h}$ which are
calculated by a function $f_{1}(\bm{x;\theta})$. $\bm{\theta}$ consists of
$\bm{W}$ and $\bm{b}$ which are the $weights$ and $biases$
repectively such that:

\begin{equation}
  \begin{split}
    h & = f_{1}(\bm{x;W,b}) \\
    \Leftrightarrow h & = \bm{W}^{T}\bm{x}+\bm{b}
  \end{split}
\end{equation}

$\bm{h}$ is then used as input for the second layer which is the output layer;
$f_{2}(\bm{h;V,c})$, with $V$ being the weigth matrix and $c$ the bias vector. 

\begin{equation}
  \begin{split}
    y & = f_{2}(\bm{h;V,c}) \\
    \Leftrightarrow y & = \bm{V}^{T}\bm{h}+\bm{c}
  \end{split}
\end{equation}

The network can be illustrated as a chain of two functions:

\begin{equation} 
  \begin{split}
  f(\bm{x;W,b,V,c}) \\
  = f_{2}(f_{1}(\bm{x}))
  \end{split}
\end{equation}

After using an affine transformation, the hidden units are computed by a
nonlinear function $g$ called an activation function:

\begin{equation} 
  h = g(\bm{W}^{T}\bm{x+b})
\end{equation}

The common activation function in deep learning is the \textbf{rectified linear
unit} or ReLU defined as:

\begin{equation} 
  g(z) = \max\{0,z\}
\end{equation}

\input{sections/scientific/fr2/relu.tex}

The complete feedforward network looks as follows:
\begin{equation} 
  \begin{split}
  f(\bm{x;W,b,V,c}) \\
  = \bm{V}^{T}\max\{0,\bm{W}^{T}\bm{x+b}\}+\bm{c}
\end{split}
\end{equation}

A representation of a single perceptron and its position in an MLP is given in
Figure~\ref{ff}.\\

\input{sections/scientific/fr2/mlpfigure.tex}

\textbf{Gradient-Based Learning.} During the training of the model, deep
learning algorithms solve an optimization problem. The problem is to minimize
the error represented by an objective function (loss).  With the loss function
the deep learning model optimizes the approximation of $f^{*}$. An example of a
loss function for MLP can be the mean squared error (MSE):\\

\begin{equation} 
  \frac{1}{n}\sum_{i=1}^n(f^*(\bm x_i)-f(\bm x_i;\bm{\theta}))^2
\end{equation}~\\

ANNs usually uses gradient-based optimizers to obtain a minimal loss function.\\


\textbf{Back-propagation.} Gradient descent is a back-propagation algorithm
which performs a backward pass through the network while adjusting the model's
parameters which are the weights and biases. It repeatedly modifies the
parameters of the units in the network to minimize the error between the
predicted and desired output vector. The algorithm passes information from the
loss function backwards through the network. It computes the gradient while
passing back the network. There are three types of gradient descent, namely
batch gradient descent, stochastic gradient descent (SGD) and mini-batch
gradient descent. Compared to batch gradient descent, SGD selects randomly a
data sample instead of a whole data batch for each backward iteration.
