\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{Goodfellow-et-al-2016}
\citation{DBLP:journals/corr/AmodeiABCCCCCCD15}
\citation{Williamsong}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Project description}{1}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Domains}{1}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}Scientific}{1}{subsubsection.2.1.1}\protected@file@percent }
\citation{Python}
\citation{chollet2015keras}
\citation{DBLP:journals/corr/abs-1804-03209}
\citation{Goodfellow-et-al-2016}
\citation{PyRo}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2}Technical}{2}{subsubsection.2.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Targeted Deliverables}{2}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}Scientific deliverables}{2}{subsubsection.2.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}Technical deliverables}{2}{subsubsection.2.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Constraints}{2}{subsection.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Pre-requisites}{2}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Scientific pre-requisites}{2}{subsection.3.1}\protected@file@percent }
\citation{mfcc}
\citation{Goodfellow-et-al-2016}
\citation{Goodfellow-et-al-2016}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Technical pre-requisites}{3}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Scientific Deliverables}{3}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Requirements}{3}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Design}{3}{subsection.4.2}\protected@file@percent }
\newlabel{mfccs}{{4.2.1}{3}{FR01: Feature extraction with MFCCs}{subsubsection.4.2.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1}FR01: Feature extraction with MFCCs}{3}{subsubsection.4.2.1}\protected@file@percent }
\newlabel{ann}{{4.2.2}{3}{FR02: Deep Learning and Artificial Neural Networks}{subsubsection.4.2.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.2}FR02: Deep Learning and Artificial Neural Networks}{3}{subsubsection.4.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.3}Deep Learning}{4}{subsubsection.4.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.4}Feedforward Neural Network}{4}{subsubsection.4.2.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The rectified linear activation function.\relax }}{4}{figure.caption.1}\protected@file@percent }
\citation{Goodfellow-et-al-2016}
\citation{Goodfellow-et-al-2016}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces A figure of a single perceptron with its position in a large-scale MLP.\relax }}{5}{figure.caption.2}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{ff}{{2}{5}{A figure of a single perceptron with its position in a large-scale MLP.\relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.5}Recurrent Neural Network}{5}{subsubsection.4.2.5}\protected@file@percent }
\newlabel{recurrentsystem}{{12}{5}{Recurrent Neural Network}{equation.4.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The recurrent system described by equation \ref  {recurrentsystem}, illustrated as an unfolded computational graph.\relax }}{5}{figure.caption.3}\protected@file@percent }
\newlabel{dag}{{3}{5}{The recurrent system described by equation \ref {recurrentsystem}, illustrated as an unfolded computational graph.\relax }{figure.caption.3}{}}
\newlabel{eqaccepting}{{13}{5}{Recurrent Neural Network}{equation.4.13}{}}
\citation{Goodfellow-et-al-2016}
\citation{Goodfellow-et-al-2016}
\citation{doi:10.1162/neco.1997.9.8.1735}
\citation{doi:10.1162/neco.1997.9.8.1735}
\citation{DBLP:journals/corr/ChungGCB14}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces RNN with no outputs, it processes the input $x$ and passes it into the state $h$ which is then passed through time. On the right graph, the same network is unfolded as a computational graph.\nobreakspace  {}\cite  {Goodfellow-et-al-2016}\relax }}{6}{figure.caption.4}\protected@file@percent }
\newlabel{unfoldrnnaccepting}{{4}{6}{RNN with no outputs, it processes the input $x$ and passes it into the state $h$ which is then passed through time. On the right graph, the same network is unfolded as a computational graph.~\cite {Goodfellow-et-al-2016}\relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces This computational graph is for calculating the training loss of an RNN which labels a sequence of input values $x$ to corresponding output values $o$. A loss function $L$ is calculating the distance from $o$ to the corresponding target $y$. On the left, the network is represented as a recurrent graph. On the right, the same network is unfolded as a computational graph.\nobreakspace  {}\cite  {Goodfellow-et-al-2016}\relax }}{6}{figure.caption.5}\protected@file@percent }
\newlabel{noutputrnn}{{5}{6}{This computational graph is for calculating the training loss of an RNN which labels a sequence of input values $x$ to corresponding output values $o$. A loss function $L$ is calculating the distance from $o$ to the corresponding target $y$. On the left, the network is represented as a recurrent graph. On the right, the same network is unfolded as a computational graph.~\cite {Goodfellow-et-al-2016}\relax }{figure.caption.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.6}Long short-term memory}{6}{subsubsection.4.2.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.7}Gated Recurrent Unit}{6}{subsubsection.4.2.7}\protected@file@percent }
\citation{DBLP:journals/corr/abs-1804-03209}
\citation{librosa}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces LSTM unit\relax }}{7}{figure.caption.6}\protected@file@percent }
\newlabel{memorycell}{{6}{7}{LSTM unit\relax }{figure.caption.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Production}{7}{subsection.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.1}Feature extraction with MFCC in Python}{7}{subsubsection.4.3.1}\protected@file@percent }
\newlabel{librosa}{{4.3.1}{7}{Feature extraction with MFCC in Python}{subsubsection.4.3.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces GRU unit.\relax }}{7}{figure.caption.7}\protected@file@percent }
\newlabel{grucell}{{7}{7}{GRU unit.\relax }{figure.caption.7}{}}
\citation{Adam}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Assessment}{8}{subsection.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.1}NFR01: Performance evaluation}{8}{subsubsection.4.4.1}\protected@file@percent }
\newlabel{assessment}{{4.4.1}{8}{NFR01: Performance evaluation}{subsubsection.4.4.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Comparison of the four models' testing results using SGD and Adam. The models were trained on the English dataset.\relax }}{8}{table.1}\protected@file@percent }
\newlabel{table:comparison}{{1}{8}{Comparison of the four models' testing results using SGD and Adam. The models were trained on the English dataset.\relax }{table.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces The testing results of the four models using Adam. The four models were trained on the English dataset. $FF$ is the abbreviation for feedforward and $acc$ stands for accuracy.\relax }}{8}{table.2}\protected@file@percent }
\newlabel{table:40}{{2}{8}{The testing results of the four models using Adam. The four models were trained on the English dataset. $FF$ is the abbreviation for feedforward and $acc$ stands for accuracy.\relax }{table.2}{}}
\citation{chollet2015keras}
\citation{chollet2015keras}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces The testing results of the four models using Adam. The four models were trained on the Luxembourgish dataset. The dataset contains 50 instances of each spoken word. FF is the abbreviation for feedforward and $acc$ stands for accuracy.\relax }}{9}{table.3}\protected@file@percent }
\newlabel{table:lux}{{3}{9}{The testing results of the four models using Adam. The four models were trained on the Luxembourgish dataset. The dataset contains 50 instances of each spoken word. FF is the abbreviation for feedforward and $acc$ stands for accuracy.\relax }{table.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Technical Deliverables}{9}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Requirements}{9}{subsection.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Design}{9}{subsection.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Production}{9}{subsection.5.3}\protected@file@percent }
\newlabel{implementation}{{5.3.1}{9}{Implementation of classification models}{subsubsection.5.3.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.1}Implementation of classification models}{9}{subsubsection.5.3.1}\protected@file@percent }
\@writefile{lol}{\contentsline {lstlisting}{sections/technical/fr1/input.py}{9}{lstlisting.-10}\protected@file@percent }
\@writefile{lol}{\contentsline {lstlisting}{sections/technical/fr1/feedforward.py}{9}{lstlisting.-11}\protected@file@percent }
\citation{teachablemachine}
\@writefile{lol}{\contentsline {lstlisting}{sections/technical/fr1/inputchange.py}{10}{lstlisting.-12}\protected@file@percent }
\@writefile{lol}{\contentsline {lstlisting}{sections/technical/fr1/rnn.py}{10}{lstlisting.-13}\protected@file@percent }
\@writefile{lol}{\contentsline {lstlisting}{sections/technical/fr1/lstm.py}{10}{lstlisting.-14}\protected@file@percent }
\@writefile{lol}{\contentsline {lstlisting}{sections/technical/fr1/gru.py}{10}{lstlisting.-15}\protected@file@percent }
\newlabel{datasetlux}{{5.3.2}{10}{FR02: Luxembourgish dataset collection}{subsubsection.5.3.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.2}FR02: Luxembourgish dataset collection}{10}{subsubsection.5.3.2}\protected@file@percent }
\bibdata{BSPS3}
\bibcite{Goodfellow-et-al-2016}{1}
\bibcite{DBLP:journals/corr/AmodeiABCCCCCCD15}{2}
\bibcite{Williamsong}{3}
\bibcite{Python}{4}
\bibcite{chollet2015keras}{5}
\bibcite{DBLP:journals/corr/abs-1804-03209}{6}
\bibcite{PyRo}{7}
\bibcite{mfcc}{8}
\bibcite{doi:10.1162/neco.1997.9.8.1735}{9}
\bibcite{DBLP:journals/corr/ChungGCB14}{10}
\bibcite{librosa}{11}
\bibcite{Adam}{12}
\bibcite{teachablemachine}{13}
\bibstyle{IEEEtran}
\@writefile{lol}{\contentsline {lstlisting}{sections/technical/fr2/ffmpeg.sh}{11}{lstlisting.-16}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Assessment}{11}{subsection.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusion}{11}{section.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{References}{11}{section*.9}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7}Appendix}{12}{section.7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Accuracy comparison between feedforward using SGD and Adam.\relax }}{12}{figure.caption.10}\protected@file@percent }
\newlabel{ffa}{{8}{12}{Accuracy comparison between feedforward using SGD and Adam.\relax }{figure.caption.10}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Feedforward's accuracy using SGD.}}}{12}{subfigure.8.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Feedforward's accuracy using Adam.}}}{12}{subfigure.8.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Loss comparison between feedforward using SGD and Adam.\relax }}{12}{figure.caption.11}\protected@file@percent }
\newlabel{ffl}{{9}{12}{Loss comparison between feedforward using SGD and Adam.\relax }{figure.caption.11}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Feedforward's loss using SGD.}}}{12}{subfigure.9.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Feedforward's loss using Adam.}}}{12}{subfigure.9.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Accuracy comparison between RNN using SGD and Adam.\relax }}{13}{figure.caption.12}\protected@file@percent }
\newlabel{rnna}{{10}{13}{Accuracy comparison between RNN using SGD and Adam.\relax }{figure.caption.12}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {RNN's accuracy using SGD.}}}{13}{subfigure.10.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {RNN's accuracy using Adam.}}}{13}{subfigure.10.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Loss comparison between RNN using SGD and Adam.\relax }}{13}{figure.caption.13}\protected@file@percent }
\newlabel{rnnl}{{11}{13}{Loss comparison between RNN using SGD and Adam.\relax }{figure.caption.13}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {RNN's loss using SGD.}}}{13}{subfigure.11.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {RNN's loss using Adam.}}}{13}{subfigure.11.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Training and validation accuracy of RNN model.\relax }}{14}{figure.caption.14}\protected@file@percent }
\newlabel{300rnna}{{12}{14}{Training and validation accuracy of RNN model.\relax }{figure.caption.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Training and validation loss of RNN model.\relax }}{14}{figure.caption.15}\protected@file@percent }
\newlabel{300rnnl}{{13}{14}{Training and validation loss of RNN model.\relax }{figure.caption.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Accuracy comparison between LSTM using SGD and Adam.\relax }}{14}{figure.caption.16}\protected@file@percent }
\newlabel{lstma}{{14}{14}{Accuracy comparison between LSTM using SGD and Adam.\relax }{figure.caption.16}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {LSTM's accuracy using SGD.}}}{14}{subfigure.14.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {LSTM's accuracy using Adam.}}}{14}{subfigure.14.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Loss comparison between LSTM using SGD and Adam.\relax }}{15}{figure.caption.17}\protected@file@percent }
\newlabel{lstml}{{15}{15}{Loss comparison between LSTM using SGD and Adam.\relax }{figure.caption.17}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {LSTM's loss using SGD.}}}{15}{subfigure.15.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {LSTM's loss using Adam.}}}{15}{subfigure.15.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Accuracy comparison between GRU using SGD and Adam.\relax }}{15}{figure.caption.18}\protected@file@percent }
\newlabel{grua}{{16}{15}{Accuracy comparison between GRU using SGD and Adam.\relax }{figure.caption.18}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {GRU's accuracy using SGD.}}}{15}{subfigure.16.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {GRU's accuracy using Adam.}}}{15}{subfigure.16.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Loss comparison between GRU using SGD and Adam.\relax }}{16}{figure.caption.19}\protected@file@percent }
\newlabel{grul}{{17}{16}{Loss comparison between GRU using SGD and Adam.\relax }{figure.caption.19}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {GRU's loss using SGD.}}}{16}{subfigure.17.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {GRU's loss using Adam.}}}{16}{subfigure.17.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Training and validation accuracy of feedforward model trained on Luxembourgish dataset.\relax }}{16}{figure.caption.20}\protected@file@percent }
\newlabel{luxffa}{{18}{16}{Training and validation accuracy of feedforward model trained on Luxembourgish dataset.\relax }{figure.caption.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces Training and validation loss of feedforward model trained on Luxembourgish dataset.\relax }}{17}{figure.caption.21}\protected@file@percent }
\newlabel{luxffl}{{19}{17}{Training and validation loss of feedforward model trained on Luxembourgish dataset.\relax }{figure.caption.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces Training and validation accuracy of RNN model trained on Luxembourgish dataset.\relax }}{17}{figure.caption.22}\protected@file@percent }
\newlabel{luxrnna}{{20}{17}{Training and validation accuracy of RNN model trained on Luxembourgish dataset.\relax }{figure.caption.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces Training and validation loss of RNN model trained on Luxembourgish dataset.\relax }}{17}{figure.caption.23}\protected@file@percent }
\newlabel{luxrnnl}{{21}{17}{Training and validation loss of RNN model trained on Luxembourgish dataset.\relax }{figure.caption.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces Training and validation accuracy of LSTM model trained on Luxembourgish dataset.\relax }}{18}{figure.caption.24}\protected@file@percent }
\newlabel{luxlstma}{{22}{18}{Training and validation accuracy of LSTM model trained on Luxembourgish dataset.\relax }{figure.caption.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces Training and validation loss of LSTM model trained on Luxembourgish dadataset.\relax }}{18}{figure.caption.25}\protected@file@percent }
\newlabel{luxlstml}{{23}{18}{Training and validation loss of LSTM model trained on Luxembourgish dadataset.\relax }{figure.caption.25}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {24}{\ignorespaces Training and validation accuracy of GRU model trained on Luxembourgish dadataset.\relax }}{18}{figure.caption.26}\protected@file@percent }
\newlabel{luxgrua}{{24}{18}{Training and validation accuracy of GRU model trained on Luxembourgish dadataset.\relax }{figure.caption.26}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {25}{\ignorespaces Training and validation loss of GRU model trained on Luxembourgish dadataset.\relax }}{19}{figure.caption.27}\protected@file@percent }
\newlabel{luxgrul}{{25}{19}{Training and validation loss of GRU model trained on Luxembourgish dadataset.\relax }{figure.caption.27}{}}
\@writefile{lol}{\contentsline {lstlisting}{sections/scientific/fr1/mfccsnippet.py}{19}{lstlisting.-17}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {26}{\ignorespaces Code snippet to extract MFCCs from the dataset.\relax }}{19}{figure.caption.28}\protected@file@percent }
\newlabel{mfccsnip}{{26}{19}{Code snippet to extract MFCCs from the dataset.\relax }{figure.caption.28}{}}
